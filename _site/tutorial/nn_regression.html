<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="John King">
<meta name="dcterms.date" content="2020-06-02">

<title>A Random Walk - Neural Network Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../tutorial/random_forest.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

<link href="../site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">
<script src="../site_libs/pagedtable-1.1/js/pagedtable.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">A Random Walk</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-tutorials" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Tutorials</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-tutorials">    
        <li>
    <a class="dropdown-item" href="../tutorial/slr.html">
 <span class="dropdown-text">Simple Linear Regression</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../tutorial/lm_assumptions.html">
 <span class="dropdown-text">Linear Model Assumptions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../tutorial/mlr.html">
 <span class="dropdown-text">Multiple Linear Regression</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../tutorial/model_selection.html">
 <span class="dropdown-text">Model Selection</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../tutorial/transform.html">
 <span class="dropdown-text">Variable Transformation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../tutorial/logistic.html">
 <span class="dropdown-text">Logistic Regression</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../tutorial/advanced.html">
 <span class="dropdown-text">Advanced Designs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../tutorial/np_anova.html">
 <span class="dropdown-text">Nonparametric ANOVA</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../tutorial/gam.html">
 <span class="dropdown-text">Generalized Additive Models</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../tutorial/svm.html">
 <span class="dropdown-text">Support Vector Machines</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../tutorial/random_forest.html">
 <span class="dropdown-text">Random Forests</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../tutorial/nn_regression.html">
 <span class="dropdown-text">Neural Network Regression</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-presentations" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Presentations</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-presentations">    
        <li>
    <a class="dropdown-item" href="../presentations/doe.qmd">
 <span class="dropdown-text">Design of Experiments</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../blog.html">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jfking50"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Neural Network Regression</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tutorial/slr.html" class="sidebar-item-text sidebar-link">Simple Linear Regression</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tutorial/lm_assumptions.html" class="sidebar-item-text sidebar-link">Linear Model Assumptions</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tutorial/mlr.html" class="sidebar-item-text sidebar-link">Multiple Linear Regression</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tutorial/model_selection.html" class="sidebar-item-text sidebar-link">Model Selection</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tutorial/transform.html" class="sidebar-item-text sidebar-link">Variable Transformation</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tutorial/logistic.html" class="sidebar-item-text sidebar-link">Logistic Regression</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tutorial/advanced.html" class="sidebar-item-text sidebar-link">Advanced Designs</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tutorial/np_anova.html" class="sidebar-item-text sidebar-link">Nonparametric ANOVA</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tutorial/gam.html" class="sidebar-item-text sidebar-link">Generalized Additive Models</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tutorial/svm.html" class="sidebar-item-text sidebar-link">Support Vector Machines</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tutorial/random_forest.html" class="sidebar-item-text sidebar-link">Random Forests</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tutorial/nn_regression.html" class="sidebar-item-text sidebar-link active">Neural Network Regression</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#neural-network-regression" id="toc-neural-network-regression" class="nav-link active" data-scroll-target="#neural-network-regression">Neural Network Regression</a>
  <ul class="collapse">
  <li><a href="#simple-neural-network-model" id="toc-simple-neural-network-model" class="nav-link" data-scroll-target="#simple-neural-network-model">Simple Neural Network Model</a></li>
  <li><a href="#gradient-descent" id="toc-gradient-descent" class="nav-link" data-scroll-target="#gradient-descent">Gradient Descent</a></li>
  <li><a href="#multiple-linear-regression" id="toc-multiple-linear-regression" class="nav-link" data-scroll-target="#multiple-linear-regression">Multiple Linear Regression</a></li>
  <li><a href="#hidden-layer" id="toc-hidden-layer" class="nav-link" data-scroll-target="#hidden-layer">Hidden Layer</a></li>
  </ul></li>
  <li><a href="#neural-network-classification" id="toc-neural-network-classification" class="nav-link" data-scroll-target="#neural-network-classification">Neural Network Classification</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Neural Network Regression</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>John King </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 2, 2020</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="neural-network-regression" class="level2">
<h2 class="anchored" data-anchor-id="neural-network-regression">Neural Network Regression</h2>
<p>Like support vector machines and tree-based models, neural networks can be applied to both regression and classification tasks. Neural networks originated in the field of neurophysiology as an attempt to model human brain activity at the neuron level <span class="citation" data-cites="mcculloch1943">(<a href="#ref-mcculloch1943" role="doc-biblioref">Warren S. McCulloch 1943</a>)</span>, but it wasn’t until the 1980s and 1990s <span class="citation" data-cites="bishop1995">(<a href="#ref-bishop1995" role="doc-biblioref">Bishop 1995</a>)</span> that they began to be developed into their current form. Neural network models are fit using a training algorithm that slowly reduces prediction error using a process called gradient descent.</p>
<section id="simple-neural-network-model" class="level3">
<h3 class="anchored" data-anchor-id="simple-neural-network-model">Simple Neural Network Model</h3>
<p>Before we get into that, let’s look at visualization of a neural network regression model in it’s simplest form: one to solve for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> given the equation <span class="math inline">\(y=\beta_0x_0+\beta_1x_1+\epsilon\)</span> where we know <span class="math inline">\(x_0=1\)</span>. Below, the two blue circles are referred to as the <strong>input layer</strong> and consist of two <strong>nodes</strong>: an input node that will be used to solve for <span class="math inline">\(\beta_1\)</span>, and a bias node to solve for <span class="math inline">\(\beta_0\)</span>, the y-intercept. Each node of the input layer is connected to the output layer, which consists of just one node because we’ll be predicting a single continuous variable, <span class="math inline">\(\hat{y}\)</span>. If this was a classification problem, and we were trying to classify the three types of irises found in the <code>iris</code> data set, then the output layer would have three nodes, each producing a probability. There is a model parameter, referred to as a <strong>weight</strong>, associated with each connected node as indicated by the <span class="math inline">\(\omega_0\)</span> and <span class="math inline">\(\omega_1\)</span> terms. The output node produces a prediction, <span class="math inline">\(\hat{y}\)</span>, using an <strong>activation function</strong>. In the case of linear regression, we use a linear activation function of the form <span class="math inline">\(f \left( \sum\limits_{h}{\omega_h} x_h \right)\)</span>. That’s it - that’s the model!</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="images/simple_nn.png" class="img-fluid figure-img" width="600"></p>
</figure>
</div>
</section>
<section id="gradient-descent" class="level3">
<h3 class="anchored" data-anchor-id="gradient-descent">Gradient Descent</h3>
<p>The algorithm used to train the model is called gradient descent, and to demonstrate how it works, we need to set the stage first. Let’s assume that we’re trying to find the <span class="math inline">\(\beta\)</span>s that have the following relationship with the predictor:</p>
<p><span class="math display">\[
y=1+0.5x+\epsilon
\]</span></p>
<p>We’ll create a data set with 10 observations and fit a linear model for comparison later.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>nn_reg <span class="ot">=</span> <span class="fu">tibble</span>(</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">runif</span>(<span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">5</span>),</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>x <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">10</span>, <span class="at">sd=</span><span class="fl">0.5</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(nn_reg, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y)) <span class="sc">+</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">formula=</span><span class="st">'y~x'</span>, <span class="at">method=</span><span class="st">'lm'</span>, <span class="at">se=</span><span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_fixed</span>(<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">5</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">5</span>)) <span class="sc">+</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Linear Model Fit"</span>) <span class="sc">+</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="nn_regression_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>nn.lm <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data=</span>nn_reg)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(nn.lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x, data = nn_reg)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.67369 -0.38063 -0.08963  0.41550  0.75801 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   0.4127     0.4516   0.914 0.387494    
x             0.7641     0.1324   5.773 0.000418 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.5164 on 8 degrees of freedom
Multiple R-squared:  0.8064,    Adjusted R-squared:  0.7822 
F-statistic: 33.32 on 1 and 8 DF,  p-value: 0.000418</code></pre>
</div>
</div>
<p>Before the model is trained, its weights are initialized with random numbers. I’ll just pick two random numbers between -1 and 1.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>(<span class="at">w0 =</span> <span class="fu">runif</span>(<span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8296121</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">w1 =</span> <span class="fu">runif</span>(<span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8741508</code></pre>
</div>
</div>
<p>Since these model parameters are just random numbers, the predictions will not be very accurate. That’s ok, though, and it’s the starting point for all untrained neural network models. We’ll go through the following iterative process to slowly train the model to make more and more accurate predictions.</p>
<p><strong>The Training Process</strong></p>
<ol type="1">
<li>Make predictions for input values.</li>
<li>Measure the difference between those predictions and the true values (called the <strong>loss</strong>).</li>
<li>Compute the partial derivative (gradient) of the loss with respect to the model parameters.</li>
<li>Update the model parameters using the partial derivative values computed in the previous step.</li>
<li>Repeat this process until the loss is either unchanged or is sufficiently low.</li>
</ol>
<p>The next several code chunks demonstrate this process one step at a time.</p>
<p><strong>Step 1. Make predictions.</strong></p>
<p>We can make predictions manually using the randomly initialized weight and bias.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>get_estimate <span class="ot">=</span> <span class="cf">function</span>(omega0, omega1){nn_reg<span class="sc">$</span>x <span class="sc">*</span> omega1 <span class="sc">+</span> omega0}</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>(<span class="at">y_hat =</span> <span class="fu">get_estimate</span>(w0, w1))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] 4.828004 4.925338 2.080258 4.459294 3.634524 3.098453 4.049059 1.418207
 [9] 3.701164 3.911277</code></pre>
</div>
</div>
<p><strong>Step 2. Calculate the loss.</strong></p>
<p>There are a number of ways we could do this, but for this example, we’ll calculate the loss by determining the mean squared error of the predictions and the target values. Mean squared error is defined as:</p>
<p><span class="math display">\[
MSE = \frac{1}{n} \sum\limits_{i=1}^{n}{\left( y_i - \hat{y}_i \right)^2}
\]</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>mse <span class="ot">=</span> <span class="cf">function</span>(predicted){<span class="dv">1</span><span class="sc">/</span><span class="fu">length</span>(predicted)<span class="sc">*</span> <span class="fu">sum</span>((nn_reg<span class="sc">$</span>y <span class="sc">-</span> predicted)<span class="sc">^</span><span class="dv">2</span>)}</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># the loss</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>(<span class="at">loss =</span> <span class="fu">mse</span>(y_hat))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8201885</code></pre>
</div>
</div>
<p><strong>Step 3. Compute the partial derivatives of the loss.</strong></p>
<p>At this point, we have two random values for <span class="math inline">\(\omega_0\)</span> and <span class="math inline">\(\omega_1\)</span> and an associated loss (error). Now we need to find new values for the ωs that will decrease the loss. How do we do that? For each ω, we need to determine whether we should increase or decrease it’s value and by how much. We determine whether to increase or decrease its value by calculating the gradient of the loss function at the current ω values. To demonstrate graphically, the loss as a function of <span class="math inline">\(\omega_0\)</span> and <span class="math inline">\(\omega_1\)</span> are plotted below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sequence of w0 values</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>Bvec <span class="ot">=</span> <span class="fu">seq</span>(<span class="at">from=</span>(w0<span class="dv">-1</span>), <span class="at">to=</span>(w0<span class="sc">+</span><span class="dv">1</span>), <span class="at">length.out =</span> <span class="dv">21</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate loss while holding w1 constant</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>Bloss <span class="ot">=</span> Bvec <span class="sc">%&gt;%</span> </span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map</span>(<span class="cf">function</span>(x) <span class="fu">get_estimate</span>(x, w1)) <span class="sc">%&gt;%</span> </span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map_dbl</span>(<span class="cf">function</span>(x) <span class="fu">mse</span>(x))</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co"># get a curve through the points and get the gradient</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>Bspl <span class="ot">=</span> <span class="fu">smooth.spline</span>(Bloss <span class="sc">~</span> Bvec)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># get the gradient at w0</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>Bgrad <span class="ot">=</span> <span class="fu">predict</span>(Bspl, <span class="at">x=</span>w0, <span class="at">deriv=</span><span class="dv">1</span>)<span class="sc">$</span>y</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co"># same thing for w1</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>Wvec <span class="ot">=</span> <span class="fu">seq</span>(<span class="at">from=</span>(w1<span class="dv">-1</span>), <span class="at">to=</span>(w1<span class="sc">+</span><span class="dv">1</span>), <span class="at">length.out =</span> <span class="dv">21</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>Wloss <span class="ot">=</span> Wvec <span class="sc">%&gt;%</span> </span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map</span>(<span class="cf">function</span>(x) <span class="fu">get_estimate</span>(w0,x)) <span class="sc">%&gt;%</span> <span class="fu">map_dbl</span>(<span class="cf">function</span>(x) <span class="fu">mse</span>(x))</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>Wspl <span class="ot">=</span> <span class="fu">smooth.spline</span>(Wloss <span class="sc">~</span> Wvec)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>Wgrad <span class="ot">=</span> <span class="fu">predict</span>(Wspl, <span class="at">x=</span>w1, <span class="at">deriv=</span><span class="dv">1</span>)<span class="sc">$</span>y</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>w0plot <span class="ot">=</span> <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>Bvec, <span class="at">y=</span>Bloss), <span class="at">color=</span><span class="st">'red'</span>, <span class="at">size=</span><span class="fl">1.5</span>) <span class="sc">+</span> </span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span><span class="fu">c</span>(w0<span class="fl">-0.5</span>, w0<span class="fl">+0.5</span>), </span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>                <span class="at">y=</span><span class="fu">c</span>(Bloss[<span class="dv">11</span>]<span class="sc">-</span>Bgrad<span class="sc">/</span><span class="dv">2</span>, Bloss[<span class="dv">11</span>]<span class="sc">+</span>Bgrad<span class="sc">/</span><span class="dv">2</span>)), </span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>            <span class="at">color=</span><span class="st">'blue'</span>, <span class="at">size=</span><span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>Bvec[<span class="dv">11</span>], <span class="at">y =</span> Bloss[<span class="dv">11</span>]), <span class="at">size=</span><span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x=</span><span class="fl">0.5</span>, <span class="at">y=</span><span class="dv">2</span>, </span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>           <span class="at">label=</span><span class="fu">paste</span>(<span class="st">"Slope ="</span>, <span class="fu">round</span>(Bgrad, <span class="dv">2</span>))) <span class="sc">+</span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_fixed</span>(<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">3.5</span>)) <span class="sc">+</span></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"w0"</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"Loss"</span>) <span class="sc">+</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>w1plot <span class="ot">=</span> <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>Wvec, <span class="at">y=</span>Wloss), <span class="at">color=</span><span class="st">'red'</span>, <span class="at">size=</span><span class="fl">1.5</span>) <span class="sc">+</span> </span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span><span class="fu">c</span>(w1<span class="fl">-0.5</span>, w1<span class="fl">+0.5</span>), </span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>                <span class="at">y=</span><span class="fu">c</span>(Wloss[<span class="dv">11</span>]<span class="sc">-</span>Wgrad<span class="sc">/</span><span class="dv">2</span>, Wloss[<span class="dv">11</span>]<span class="sc">+</span>Wgrad<span class="sc">/</span><span class="dv">2</span>)), </span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>            <span class="at">color=</span><span class="st">'blue'</span>, <span class="at">size=</span><span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>Wvec[<span class="dv">11</span>], <span class="at">y=</span>Wloss[<span class="dv">11</span>]), <span class="at">size=</span><span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x=</span><span class="fl">1.4</span>, <span class="at">y=</span><span class="fl">0.5</span>, <span class="at">label=</span><span class="fu">paste</span>(<span class="st">"Slope ="</span>, <span class="fu">round</span>(Wgrad, <span class="dv">2</span>))) <span class="sc">+</span></span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_fixed</span>(<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">3.5</span>)) <span class="sc">+</span></span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"w1"</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"Loss"</span>) <span class="sc">+</span></span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(w0plot, w1plot, <span class="at">nrow=</span><span class="dv">1</span>, <span class="at">ncol=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="nn_regression_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>In practice, the partial derivatives are calculated as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">Bpartial =</span> <span class="fu">sum</span>(<span class="sc">-</span>(nn_reg<span class="sc">$</span>y <span class="sc">-</span> y_hat)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7.670526</code></pre>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">Wpartial =</span> <span class="fu">sum</span>(<span class="sc">-</span>(nn_reg<span class="sc">$</span>y <span class="sc">-</span> y_hat) <span class="sc">*</span> nn_reg<span class="sc">$</span>x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 26.07812</code></pre>
</div>
</div>
<p><strong>Step 4. Update the model parameters.</strong></p>
<p>From the above plots, we can see that to decrease the loss, we need to decrease both <span class="math inline">\(\omega\)</span>s. In fact, the following rules always apply:</p>
<ul>
<li><p>With a <em>positive</em> gradient, <em>decrease</em> the parameter value.</p></li>
<li><p>With a <em>negative</em> gradient, <em>increase</em> the parameter value.</p></li>
</ul>
<p>We know we need to decrease the parameter values, so now we need to determine <em>how much</em> to decrease them. Right now, all we have to go on are the magnitude of the gradients. If we decreased the parameters by their respective gradients, the new parameter values would be far to the left on both plots above - we would overshoot the bottom of the curve in both cases. Instead of using the full gradient value, it appears that the parameters should be updated as follows:</p>
<p><span class="math display">\[
\omega_{new} = (\omega_{old}) - (\omega_{gradient})(\alpha)
\]</span></p>
<p>Where <span class="math inline">\(\alpha\)</span> is a multiplier in the range [0, 1], and is referred to as the <strong>learning rate</strong>. For our example, an α of 0.01 will suffice, but keep in mind that α is a hyperparameter that often must be tuned. The code below selects <span class="math inline">\(\alpha\)</span>, updates the parameter values, and recalculates the loss. Notice that the loss has decreased as expected.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">=</span> <span class="fl">0.001</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>w0 <span class="ot">=</span> w0 <span class="sc">-</span> Bpartial <span class="sc">*</span> alpha</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>w1 <span class="ot">=</span> w1 <span class="sc">-</span> Wpartial <span class="sc">*</span> alpha</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mse</span>(<span class="fu">get_estimate</span>(w0, w1))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.6816571</code></pre>
</div>
</div>
<p>Next we’ll put all this in a loop, iterate through a number of times, and see what we get for parameter estimates. I’ll start from the beginning and capture the parameters and loss as training progresses through 5000 iterations. Below, the parameter estimates are plotted for each iteration and compared to the linear model coefficients.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>w0 <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>w1 <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">=</span> <span class="fl">0.001</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>w0s <span class="ot">=</span> w0</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>w1s <span class="ot">=</span> w1</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>){</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(nn_reg)){</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="ot">=</span> <span class="fu">get_estimate</span>(w0, w1)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    Bgrad <span class="ot">=</span> <span class="fu">sum</span>(<span class="sc">-</span>(nn_reg<span class="sc">$</span>y <span class="sc">-</span> y_hat))</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    Wgrad <span class="ot">=</span> <span class="fu">sum</span>(<span class="sc">-</span>(nn_reg<span class="sc">$</span>y <span class="sc">-</span> y_hat) <span class="sc">*</span> nn_reg<span class="sc">$</span>x)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    w0 <span class="ot">=</span> w0 <span class="sc">-</span> Bgrad <span class="sc">*</span> <span class="fl">0.001</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    w1 <span class="ot">=</span> w1 <span class="sc">-</span> Wgrad <span class="sc">*</span> <span class="fl">0.001</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    w0s <span class="ot">=</span> <span class="fu">c</span>(w0s, w0)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    w1s <span class="ot">=</span> <span class="fu">c</span>(w1s, w1)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>wHistory <span class="ot">=</span> <span class="fu">tibble</span>(</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(w0s),</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">b =</span> w0s,</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">w =</span> w1s</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gganimate)</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(wHistory) <span class="sc">+</span></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>iter, <span class="at">y=</span>w0s, <span class="at">color=</span><span class="st">'w_0 Estimate'</span>, <span class="at">group=</span><span class="fu">seq_along</span>(iter))) <span class="sc">+</span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept=</span><span class="fu">coef</span>(nn.lm)[<span class="dv">1</span>]) <span class="sc">+</span> </span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x=</span><span class="dv">1200</span>, <span class="at">y=</span><span class="fl">0.43</span>, <span class="at">label=</span><span class="st">"Linear Model Intercept Coefficient"</span>) <span class="sc">+</span></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>iter, <span class="at">y=</span>w1s, <span class="at">color=</span><span class="st">'w_1 Estimate'</span>, <span class="at">group=</span><span class="fu">seq_along</span>(iter))) <span class="sc">+</span></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept=</span><span class="fu">coef</span>(nn.lm)[<span class="dv">2</span>]) <span class="sc">+</span> </span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x=</span><span class="dv">1300</span>, <span class="at">y=</span><span class="fl">0.785</span>, <span class="at">label=</span><span class="st">"Linear Model Slope Coefficient"</span>) <span class="sc">+</span></span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">name=</span><span class="st">"Legend"</span>, <span class="at">values=</span><span class="fu">c</span>(<span class="st">'blue'</span>, <span class="st">'red'</span>)) <span class="sc">+</span> </span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Iteration"</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"Parameter Value"</span>) <span class="sc">+</span></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transition_reveal</span>(iter)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="nn_regression_files/figure-html/unnamed-chunk-10-1.gif" class="img-fluid"></p>
</div>
</div>
<p>To visualize the gradient descent methodology, calculate the loss for a range of <span class="math inline">\(\omega_0\)</span> and <span class="math inline">\(\omega_1\)</span> values and plot the loss function as a surface.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="ot">=</span> <span class="fu">expand_grid</span>(<span class="at">bs=</span><span class="fu">seq</span>(<span class="fl">0.3</span>,<span class="fl">0.9</span>,<span class="at">length.out=</span><span class="dv">20</span>), <span class="at">ws=</span><span class="fu">seq</span>(<span class="fl">0.5</span>,<span class="dv">1</span>,<span class="at">length.out=</span><span class="dv">20</span>))</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>loss_fn<span class="sc">$</span>Loss <span class="ot">=</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(loss_fn) <span class="sc">%&gt;%</span> </span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map</span>(<span class="cf">function</span>(x) <span class="fu">get_estimate</span>(loss_fn[x,<span class="st">'bs'</span>] <span class="sc">%&gt;%</span> .<span class="sc">$</span>bs, loss_fn[x,<span class="st">'ws'</span>]<span class="sc">%&gt;%</span> .<span class="sc">$</span>ws)) <span class="sc">%&gt;%</span> </span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map_dbl</span>(<span class="cf">function</span>(x) <span class="fu">mse</span>(x))</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(wHistory) <span class="sc">+</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_raster</span>(<span class="at">data=</span>loss_fn, <span class="fu">aes</span>(<span class="at">x=</span>bs, <span class="at">y=</span>ws, <span class="at">fill=</span>Loss)) <span class="sc">+</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_contour</span>(<span class="at">data=</span>loss_fn, <span class="fu">aes</span>(<span class="at">x=</span>bs, <span class="at">y=</span>ws, <span class="at">z=</span>Loss), <span class="at">color=</span><span class="st">'white'</span>, <span class="at">bins=</span><span class="dv">28</span>) <span class="sc">+</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>b, <span class="at">y=</span>w, <span class="at">group=</span><span class="fu">seq_along</span>(iter)), <span class="at">color=</span><span class="st">'yellow'</span>, <span class="at">size=</span><span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Intercept"</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"Slope"</span>) <span class="sc">+</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transition_time</span>(iter) <span class="sc">+</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="fu">paste</span>(<span class="st">"Gradient Descent Iteration:"</span>, <span class="st">"{round(frame_time, 0)}"</span>)) <span class="sc">+</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">shadow_wake</span>(<span class="at">wake_length =</span> <span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="nn_regression_files/figure-html/unnamed-chunk-11-1.gif" class="img-fluid"></p>
</div>
</div>
<p>We can also see the regression line update as training progresses.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(wHistory) <span class="sc">+</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">data=</span>nn_reg, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y), <span class="at">formula=</span><span class="st">'y~x'</span>, <span class="at">method=</span><span class="st">'lm'</span>, <span class="at">se=</span><span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="fu">aes</span>(<span class="at">intercept=</span>b, <span class="at">slope=</span>w), <span class="at">color=</span><span class="st">'red'</span>) <span class="sc">+</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data=</span>nn_reg, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y)) <span class="sc">+</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_fixed</span>(<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">5</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">5</span>)) <span class="sc">+</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transition_time</span>(iter) <span class="sc">+</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="fu">paste</span>(<span class="st">"Gradient Descent Iteration:"</span>, <span class="st">"{round(frame_time, 0)}"</span>)) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="nn_regression_files/figure-html/unnamed-chunk-12-1.gif" class="img-fluid"></p>
</div>
</div>
<p>Let’s compare the final parameter estimates from the neural network model to the linear model coefficients.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">Model =</span> <span class="fu">c</span>(<span class="st">"Linear"</span>, <span class="st">"Neural Network"</span>),</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">w_0 =</span> <span class="fu">c</span>(<span class="fu">coef</span>(nn.lm)[<span class="dv">1</span>], <span class="fu">tail</span>(w0s, <span class="dv">1</span>)),</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">w_1 =</span> <span class="fu">c</span>(<span class="fu">coef</span>(nn.lm)[<span class="dv">2</span>], <span class="fu">tail</span>(w1s, <span class="dv">1</span>))</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["Model"],"name":[1],"type":["chr"],"align":["left"]},{"label":["w_0"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["w_1"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"Linear","2":"0.4127478","3":"0.7640741"},{"1":"Neural Network","2":"0.4135672","3":"0.7638478"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>There are a variety of <em>R</em> packages to simplify the process of fitting a neural network model. Since we’re doing regression and not something for complicated like image classification, natural language processing, or reinforcement learning, a package like <code>nnet</code> provides everything we need.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>nnModel <span class="ot">=</span> nnet<span class="sc">::</span><span class="fu">nnet</span>(y <span class="sc">~</span> x, <span class="at">data =</span> nn_reg,   <span class="co"># formula notation is the same as lm()</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">linout =</span> <span class="cn">TRUE</span>,          <span class="co"># specifies linear output (instead of logistic)</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">decay =</span> <span class="fl">0.001</span>,          <span class="co"># weight decay</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>                     <span class="at">maxit =</span> <span class="dv">100</span>,            <span class="co"># stop training after 100 iterations</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>                     <span class="at">size =</span> <span class="dv">0</span>, <span class="at">skip =</span> <span class="cn">TRUE</span>)  <span class="co"># no hidden layer (covered later)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># weights:  2
initial  value 31.444863 
final  value 2.134476 
converged</code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(nnModel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>a 1-0-1 network with 2 weights
options were - skip-layer connections  linear output units  decay=0.001
 b-&gt;o i1-&gt;o 
 0.41  0.76 </code></pre>
</div>
</div>
<p>From the model summary, we see that has two weights: one for <span class="math inline">\(\omega_0\)</span> and one for <span class="math inline">\(\omega_1\)</span>. The initial and final values are model error terms. Converged means that training stopped before it reached <code>maxit</code>. The model takes the form 1-0-1, which means it has one input node (the bias, or intercept, node is automatically included) in the input layer, 0 nodes in the hidden layer (we’ll cover hidden layers later), and one node in the output layer. The <code>b-&gt;o</code> term is our <span class="math inline">\(\omega_0\)</span> (intercept) parameter value, and <code>i1-&gt;o</code> is our <span class="math inline">\(\omega_1\)</span> (slope) parameter value. We can extract the coefficients the usual way.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(nnModel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     b-&gt;o     i1-&gt;o 
0.4125070 0.7641276 </code></pre>
</div>
</div>
</section>
<section id="multiple-linear-regression" class="level3">
<h3 class="anchored" data-anchor-id="multiple-linear-regression">Multiple Linear Regression</h3>
<p>The neural network model can be easily expanded to accommodate additional predictors by adding a node to the input layer for each additional predictor and connecting it to the output node. Below is a comparison of coefficients obtained from a linear model and a neural network model for a data set with three predictors.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make up data</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>mlr <span class="ot">=</span> <span class="fu">tibble</span>(</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">runif</span>(<span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">5</span>),</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> <span class="fu">runif</span>(<span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">5</span>),</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">x3 =</span> <span class="fu">runif</span>(<span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">5</span>),</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>x1 <span class="sc">-</span> <span class="fl">0.5</span><span class="sc">*</span>x2 <span class="sc">+</span> x3 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">10</span>, <span class="at">sd=</span><span class="fl">0.5</span>)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co"># linear model coefficients</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(y <span class="sc">~</span> ., <span class="at">data=</span>mlr))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)          x1          x2          x3 
  2.0447549   0.5355719  -0.7312496   0.8035532 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># neural network coefficients</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(nnet<span class="sc">::</span><span class="fu">nnet</span>(y <span class="sc">~</span> ., <span class="at">data =</span> mlr, <span class="at">linout =</span> <span class="cn">TRUE</span>, <span class="at">decay =</span> <span class="fl">0.001</span>, <span class="at">maxit =</span> <span class="dv">100</span>,</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">size =</span> <span class="dv">0</span>, <span class="at">skip =</span> <span class="cn">TRUE</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># weights:  4
initial  value 195.927838 
final  value 4.149504 
converged</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>      b-&gt;o      i1-&gt;o      i2-&gt;o      i3-&gt;o 
 2.0399505  0.5361400 -0.7307887  0.8040190 </code></pre>
</div>
</div>
<p>If you think this seems like overkill just to model a linear relationship between two variables, I’d agree with you. But consider this:</p>
<ul>
<li><p>What if the relationship between two variables isn’t linear?</p></li>
<li><p>What if there are dozens of predictor variables and dozens of response variables and the underlying relationships are highly complex?</p></li>
</ul>
<p>In cases like these, neural networks models can be very beneficial. To make that leap, however, we need to give our neural network model more power by giving it the ability to model these complexities. We do that by adding one or more <strong>hidden layers</strong> to the model.</p>
</section>
<section id="hidden-layer" class="level3">
<h3 class="anchored" data-anchor-id="hidden-layer">Hidden Layer</h3>
<p>Neural network models become <strong>universal function approximators</strong> with the addition of one or more hidden layers. Hidden layers fall between the input layer and the output layer. Adding more predictor variables and one hidden layer, we get the following network.</p>
<div id="hidden_net" class="quarto-figure quarto-figure-left anchored">
<figure class="figure">
<p><img src="images/hidden_nn.png" class="img-fluid figure-img" width="800"></p>
</figure>
</div>
<p>We’ve introduced a new variable ν, and a new function <em>u</em>. The ν variables are trainable weights just like the <em>w</em> variables. The <em>u</em> functions are activation functions as described earlier. Typically, all nodes in a hidden layer share a common type of activation function. A variety of activation functions have been developed, a few of which are shown below. For many applications, a rectified linear, activation function is a good choice for hidden layers.</p>
<table class="table">
<colgroup>
<col style="width: 31%">
<col style="width: 43%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Activation Function</th>
<th>Activation Function Formula</th>
<th>Output Type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Threshold</td>
<td><span class="math inline">\(f(u) = \begin{Bmatrix} 1, u\gt0 \\ 0, u\le0 \end{Bmatrix}\)</span></td>
<td>Binary</td>
</tr>
<tr class="even">
<td>Linear</td>
<td><span class="math inline">\(f(u) = u\)</span></td>
<td>Numeric</td>
</tr>
<tr class="odd">
<td>Logistic</td>
<td><span class="math inline">\(f(u) = \frac{e^u}{1+e^u}\)</span></td>
<td>Numeric Between 0 &amp; 1</td>
</tr>
<tr class="even">
<td>Rectified Linear</td>
<td><span class="math inline">\(f(u) = \begin{Bmatrix} u, u\gt0 \\ 0, u\le0 \end{Bmatrix}\)</span></td>
<td>Numeric Positive</td>
</tr>
</tbody>
</table>
<p>As stated, adding a hidden layer turns the neural network model into a universal function approximator. For the case of regression, we can think of this as giving the neural network the ability to model non-linear functions without knowing what the nature of the nonlinear relationship is. Compare that to linear regression. If we had the relationship <span class="math inline">\(y=x^2\)</span>, we would need to transform either the response or predictor variable in a linear regression model, and this requires knowing the order of the polynomial to get a good fit. With neural network regression, we don’t need this knowledge. Instead, we allow the hidden layer to learn the nature of the relationship through the model training process. To demonstrate, we’ll use the <code>exa</code> data set from the <code>faraway</code> package, which looks like this.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>exa <span class="ot">=</span> faraway<span class="sc">::</span>exa</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(exa) <span class="sc">+</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>m), <span class="at">color=</span><span class="st">'red'</span>, <span class="at">size=</span><span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y)) <span class="sc">+</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Simulated Data (Black) and True Function (Red)"</span>) <span class="sc">+</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="nn_regression_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>To fit a linear model with a 10-node hidden layer, we specify <code>size = 10</code>, and since 100 iterations might not be enough to converge, we’ll increase <code>maxit</code> to 500. Otherwise, everything else is the same. With 2 nodes in the input layer (1 for the bias, 1 for x) and 11 nodes in the hidden layer (1 for the bias, and 10 for those we specified), the model will have 31 weights to train.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>nnModel2 <span class="ot">=</span> nnet<span class="sc">::</span><span class="fu">nnet</span>(y <span class="sc">~</span> x, <span class="at">data =</span> exa, <span class="at">linout =</span> <span class="cn">TRUE</span>, <span class="at">decay =</span> <span class="dv">10</span><span class="sc">^</span>(<span class="sc">-</span><span class="dv">4</span>), <span class="at">maxit =</span> <span class="dv">500</span>, <span class="at">size =</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># weights:  31
initial  value 499.220789 
iter  10 value 78.378021
iter  20 value 48.290911
iter  30 value 40.726235
iter  40 value 27.840931
iter  50 value 26.694405
iter  60 value 25.771768
iter  70 value 25.636428
iter  80 value 25.582253
iter  90 value 25.475199
iter 100 value 25.237757
iter 110 value 24.502290
iter 120 value 24.125822
iter 130 value 23.715466
iter 140 value 23.644963
iter 150 value 23.592656
iter 160 value 23.541215
iter 170 value 23.460968
iter 180 value 23.394390
iter 190 value 23.326002
iter 200 value 23.299889
iter 210 value 23.294752
iter 220 value 23.253858
iter 230 value 23.176888
iter 240 value 23.124385
iter 250 value 23.104052
iter 260 value 23.084055
iter 270 value 23.080214
iter 280 value 23.078985
iter 290 value 23.076738
iter 300 value 23.074305
iter 310 value 23.073038
iter 320 value 23.072321
final  value 23.071986 
converged</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">=</span> <span class="fu">predict</span>(nnModel2, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">x=</span>exa<span class="sc">$</span>x))</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data=</span>exa, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>m, <span class="at">color=</span><span class="st">'True Function'</span>), <span class="at">size=</span><span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>exa<span class="sc">$</span>x, <span class="at">y=</span>preds, <span class="at">color=</span><span class="st">'Model Fit'</span>), <span class="at">size=</span><span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data=</span>exa, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y)) <span class="sc">+</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">name=</span><span class="st">"Legend"</span>, <span class="at">values=</span><span class="fu">c</span>(<span class="st">'blue'</span>, <span class="st">'red'</span>)) <span class="sc">+</span> </span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="nn_regression_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The plot above indicates the model over fit the data somewhat, although we only know this because we have the benefit of knowing the true function. We could reduce the amount of over fitting by choosing different hyperparameter values (decay, or the number of hidden layer nodes) or by changing the default training stopping criteria.</p>
<p>The trained model’s weights are saved with the model, and all 31 are shown below. This highlights a significant drawback of neural network regression. Earlier when we used a neural network model to estimate the slope and intercept, the model weights had meaning: we could directly interpret the weights as slope and intercept. How do we interpret the weights below? I have no idea! The point is that neural network models can be trained to make highly accurate predictions…but at the cost of interpretability.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>nnModel2<span class="sc">$</span>wts</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] -16.5006608  20.3693099 -29.4278236  34.4051715 -20.7471248  28.4091270
 [7] -29.1180265  40.7327613   2.3060868   1.9215748  -1.0624319   2.9527926
[13]   2.8259165 -15.1652645   1.6957639   0.5958946   3.7441769 -21.0803998
[19]   6.3092685  -8.3407380   1.3998851  19.2726000 -11.2056916 -23.2575100
[25]   9.5932587   2.2295197   3.1400221   6.4367782   0.4575623  -4.5860998
[31]  -6.2028427</code></pre>
</div>
</div>
</section>
</section>
<section id="neural-network-classification" class="level2">
<h2 class="anchored" data-anchor-id="neural-network-classification">Neural Network Classification</h2>
<p>Neural network models have been extremely successful when applied to classification tasks such as image classification and natural language processing. These models are highly complex and are built using sophisticated packages such as TensorFlow (developed by Google) and PyTorch (developed by Facebook). Building complex models for those kinds of classification tasks are beyond the scope of this tutorial. Instead, this section provides a high-level overview of classification using the <code>nnet</code> package and the <code>iris</code> data set.</p>
<p>The neural network training algorithm for classification is the same as for regression, but for classification, we need to change some of the attributes of the model itself. Instead of a linear activation function in the output layer, we need to use the softmax function. Doing so will cause the output layer to produce probabilities for each of the three flower species (this is accomplished by simply removing <code>linout = TRUE</code> from the <code>nnet()</code> function. Additionally, we use a categorical cross entropy loss function instead of mean squared error. Below, I also set <code>rang = 0.1</code> to scale the predictors to be in the range recommended in the function help. We’ll also create the same training/test split as in the non-parametric regression chapter so we can directly compare results.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a training and a test set</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">0</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> caTools<span class="sc">::</span><span class="fu">sample.split</span>(iris, <span class="at">SplitRatio =</span> <span class="fl">0.8</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>iris_train <span class="ot">=</span> <span class="fu">subset</span>(iris, train <span class="sc">==</span> <span class="cn">TRUE</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>iris_test <span class="ot">=</span> <span class="fu">subset</span>(iris, train <span class="sc">==</span> <span class="cn">FALSE</span>)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co"># train the model</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>irisModel <span class="ot">=</span> nnet<span class="sc">::</span><span class="fu">nnet</span>(Species <span class="sc">~</span> ., <span class="at">data =</span> iris_train, </span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>                       <span class="at">size=</span><span class="dv">2</span>,       <span class="co"># only two nodes in the hidden layer</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>                       <span class="at">maxit=</span><span class="dv">200</span>,    <span class="co"># stopping criteria</span></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>                       <span class="at">entropy=</span><span class="cn">TRUE</span>, <span class="co"># switch for entropy</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>                       <span class="at">decay=</span><span class="fl">5e-4</span>,   <span class="co"># weight decay hyperparameter</span></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>                       <span class="at">rang=</span><span class="fl">0.1</span>)     <span class="co"># scale input values</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># weights:  19
initial  value 131.916499 
iter  10 value 75.933787
iter  20 value 56.873818
iter  30 value 55.958531
iter  40 value 55.852468
iter  50 value 55.797951
iter  60 value 51.382669
iter  70 value 11.286807
iter  80 value 7.667108
iter  90 value 7.657444
iter 100 value 7.643547
iter 110 value 7.642436
iter 120 value 7.641672
iter 130 value 7.640995
iter 140 value 7.640338
iter 150 value 7.627436
iter 160 value 7.377487
iter 170 value 5.671710
iter 180 value 4.882362
iter 190 value 4.810287
iter 200 value 4.793128
final  value 4.793128 
stopped after 200 iterations</code></pre>
</div>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make predictions on test data</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>iris_preds <span class="ot">=</span> <span class="fu">predict</span>(irisModel, <span class="at">newdata=</span>iris_test)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(iris_preds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      setosa  versicolor    virginica
5  0.9956710 0.004329043 6.376970e-16
10 0.9911190 0.008881042 2.881866e-15
15 0.9976175 0.002382547 1.824318e-16
20 0.9957198 0.004280170 6.226948e-16
25 0.9739313 0.026068739 2.794827e-14
30 0.9901521 0.009847885 3.581197e-15</code></pre>
</div>
</div>
<p>This first six predictions for the test set are shown above, and notice that the values are in fact probabilities. The model is highly confident that each one of these first six predictions are setosa. Recall from the SVM and CART sections of the non-parametric regression chapter that both of those models misclassified test set observations #24 and #27 as versicolor that are actually virginica. Below we see that the neural network model correctly predicts both observations but is less confident about observation #24.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>iris_preds[<span class="fu">c</span>(<span class="dv">24</span>,<span class="dv">27</span>), ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          setosa versicolor virginica
120 7.349090e-11 0.18967040 0.8103296
135 5.460005e-13 0.03105806 0.9689419</code></pre>
</div>
</div>
<p>The confusion matrix for the entire test set reveals that the model has an accuracy of 100%.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>iris_cm <span class="ot">=</span> cvms<span class="sc">::</span><span class="fu">confusion_matrix</span>(</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">targets =</span> iris_test[, <span class="dv">5</span>], </span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">predictions =</span> <span class="fu">colnames</span>(iris_preds)[<span class="fu">max.col</span>(iris_preds)])</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>cvms<span class="sc">::</span><span class="fu">plot_confusion_matrix</span>(iris_cm<span class="sc">$</span><span class="st">`</span><span class="at">Confusion Matrix</span><span class="st">`</span>[[<span class="dv">1</span>]], <span class="at">add_zero_shading =</span> <span class="cn">FALSE</span>) <span class="sc">+</span> </span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Neural Network Confusion Matrix"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="nn_regression_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid" width="672"></p>
</div>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-bishop1995" class="csl-entry" role="doc-biblioentry">
Bishop, Christopher. 1995. <em>Neural Networks for Pattern Recognition</em>. Oxford University Press.
</div>
<div id="ref-mcculloch1943" class="csl-entry" role="doc-biblioentry">
Warren S. McCulloch, Walter H. Pitts. 1943. <span>“A Logical Calculus of the Ideas Immanent in Nervous Activity.”</span> <em>Bulletin of Mathematical Biophysics</em> 5.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'alternate';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../tutorial/random_forest.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Random Forests</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Copyright 2022, John King</div>   
  </div>
</footer>



</body></html>